Lab notebook

Dag 1 
Försöker förstå hur datan kommer att se ut.
gjorde en liten script file och använde head för att läsa de 10 första raderna och skickade detta 
till gunzip. Försöker förstå hur datan kommer att se ut.
head overlaps.m4.gz | gunzip | file0.txt 
head -n kan sätta n till olika värden. 
awk '{print $1,$2,$6,$7,$10,$11}' file1.txt | cat > file2.txt funderar på att göra något liknande så man bara skickar med den relevanta informationen? 
more overlaps.m4.gz

Dag 2
Ska nog använda hashmap. String.hashCode för att få ett unikt heltal från identifierarna. Problemet är att vi kan råka få samma tal från olika strängar.
Frågor: spara noder och kanter? om vi räknar en kant en gång, kommer vi råka dubbelräkna denna kant?
more overlaps.m4.gz | grep fp.3.Luci_12D10.ctg.ctg7180000088249
Funderar på om jag ska dela upp filen i mindre delar eventuellt skicka in enbart den information som behövs.
Har gjort några testfiler av olika storlekar som jag kör med. kan en kant förekomma två gånger? Det kan bli ett problem.
Vill veta antalet kanter, grad distrubitionen mellan noder, komponenter med minst tre noder och andelen av dessa som är cliques. 
components är alla delgrafer och cliques är kompletta delgrafer. där alla noder sitter ihop med varandra som jag har förstått det 
min första tanke spara alla noder som nycklar och dess grannar som värden i en hashmap. Typ en arraylist med alla grannar. Funderar på hur jag ska översätta identifierarna till heltal.


Dag 3
körde gunzip på hela filen. 
awk '{if (($7- $6 > 1000) && ($11 -$10 > 1000 )) print $1}' overlaps.m4 | wc -l  
Nu vet jag antalet kanter. 63920640.
För att översätta sträng identifierarna till heltal sparar jag de som nycklar i en hashmap och har en counter som ökar varje gång som den stöter på en sträng för 
första gången. Har implementerat en funktion som läser filen rad för rad. Detta tar ungefär 140 ms för en fil 
med 8 lines. Den sparar även grafen som en ArrayList med en ArrayList på varje index. identifierare 0 representeras av index 0 i listan. 
där sparas en lista med alla dess grannar. Har även skapat en djupet-först-sökning funktion. Fuktionen tar enbart ca 3 ms för filen med 8 lines. Så om något 
ska förbättras måste det vara den första funktionen. Påverkas mycket av hur stor graf som ska skapas. grafen måste initsialiseras så att alla noder får plats men görs den för stor kommer den ta för mycket utrymme. För en graf med 10 miljoner noder tar det 1123 ms och för en graf
med 100 miljoner går det inte ( out of memory: java heap space)
för på en fil med 7 rader tar depthfirstsearch 98 ms. på en fil med 85 rader 144 ms. på en fil med 1063 rader tar det 199 ms.  (har nu satt grafen till 10 milj noder)
När Grafen sparades som ArrayList<ArrayList<int>> (1063 rader) 1013 ms. När grafen sparas som LinkedList<Integer> adj[] (också en linkedlist) read: 986 ms, dfs: 24 ms. 

Dag 4
overlaps.m4 har 64 056 772 rader. När jag försökte köra mitt program på den riktiga filen: java.lang.OutOfMemoryError: Java heap space
försökte med Graph2 (linkedlist): java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects. 
Försökte öka heapspace med "vmArgs": "-Xmx4048m",  i launch.json filen.
Den stannar på 26 milj. Ökade till 8048. Nu funkar det.63920640

numberOfEdges: 63962895
Time for task read: 18964512 ms
Time for task depthfirstsearch: 0 ms
Time for task histogram: 13512 ms

number of nodes: 11393435
Nu vet jag antalet noder så ändrar Grafen till en storlek av 11393435 +1. Programmet går nu snabbare. Uppkommer problem när jag kör depthfirstsearch på grafen. 
När det är rekursion läggs allt på en stack så jag ökar storleken med -Xss515m. Det fungerar nu.

number of components: 317284
number of cliques: 35472
Time for task read: 5460931 ms
Time for task depthfirstsearch: 312982 ms
Time for task histogram: 0 ms

Dag 5
Försöker föbättra min funktion samt tänka på tidskomplexiteten. Har gjort allt med arraylistor men insett att den kanske skulle köra effektivare med linkedlist? 
Arraylistor måste hela tiden 'rezisas' vilket är onödigt. Dock går det mycket snabbare att komma åt elementen, vet dock inte vad jag borde prioritera. 
Testkörde en gång utan att skapa graf 
Time for task read: 1817930 ms

Time for task read: 7655093 ms
Time for task histogram: 0 ms
Time for task depthfirstsearch: 1117613 ms

testade att istället ha en hashmap som räknar grannar så räknade jag för varje nod i grafen storleken på grannlistan. Detta verkar ta längre tid dock. 



private String reEncode(String identifier) {
		byte ptext[] = identifier.getBytes();
		String value = new String(ptext, StandardCharsets.US_ASCII);
		return value;
	}

if (truorfalse=true) { //enough for new edge 
			numberOfEdges= numberOfEdges +1;

	 		if ( edges.get(identifier1) != null  ) { //if it already exists
				ArrayList<String> edgelist = edges.get(identifier1);
				edgelist.add(identifier2);
				edges.put(identifier1, edgelist); } // put first and second vertex into counter
		    else {
				edges.put(identifier1, 1);
			}		
			
	}
        scan.close(); 
String identifier1 = scan.next(); //first identifier
		String identifier2 = scan.next(); //second 
		int start1 = scan.nextInt();
		int end1 = scan.nextInt();
		int start2 = scan.nextInt();
		int end2 = scan.nextInt();

if (identifier.contains("fp.3.Luci")) {
			identifier = identifier.substring()
		}
		else if (identifier.contains("fermi")) {

		}
		else if (identifier.contains("contig")) {
			
		}
		else {

		}
  public void dfs() {
        boolean[] isVisited = new boolean[V];
        for (int v=0; v<V; v++) {
          v.visited =false; 
        }
        for (int v=0; v<V; v++){
          if (!v.visited) {
            dfsVisit(v)
          
        }
      }

      private void dfsVisit(int v){
        v.visited = true; 
        for u in neighbor v
        if not u.visited
          dfsVisit(u);

      }

