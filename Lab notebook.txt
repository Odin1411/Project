Lab notebook

Dag 1 
Försöker förstå hur datan kommer att se ut.
gjorde en liten script file och använde head för att läsa de 10 första raderna och skickade detta 
till gunzip. Försöker förstå hur datan kommer att se ut.
head overlaps.m4.gz | gunzip | file0.txt 
head -n kan sätta n till olika värden. 
awk '{print $1,$2,$6,$7,$10,$11}' file1.txt | cat > file2.txt funderar på att göra något liknande så man bara skickar med den relevanta informationen? 
more overlaps.m4.gz

Dag 2
Ska nog använda hashmap. String.hashCode för att få ett unikt heltal från identifierarna. Problemet är att vi kan råka få samma tal från olika strängar.
Frågor: spara noder och kanter? om vi räknar en kant en gång, kommer vi råka dubbelräkna denna kant?
more overlaps.m4.gz | grep fp.3.Luci_12D10.ctg.ctg7180000088249
Funderar på om jag ska dela upp filen i mindre delar eventuellt skicka in enbart den information som behövs.
Har gjort några testfiler av olika storlekar som jag kör med. kan en kant förekomma två gånger? Det kan bli ett problem.
Vill veta antalet kanter, grad distrubitionen mellan noder, komponenter med minst tre noder och andelen av dessa som är cliques. 
components är alla delgrafer och cliques är kompletta delgrafer. där alla noder sitter ihop med varandra som jag har förstått det 
min första tanke spara alla noder som nycklar och dess grannar som värden i en hashmap. Typ en arraylist med alla grannar. Funderar på hur jag ska översätta identifierarna till heltal.


Dag 3
körde gunzip på hela filen. 
awk '{if (($7- $6 > 1000) && ($11 -$10 > 1000 )) print $1}' overlaps.m4 | wc -l  
Nu vet jag antalet kanter. 63920640.
För att översätta sträng identifierarna till heltal sparar jag de som nycklar i en hashmap och har en counter som ökar varje gång som den stöter på en sträng för 
första gången. Har implementerat en funktion som läser filen rad för rad. Detta tar ungefär 140 ms för en fil 
med 8 lines. Den sparar även grafen som en ArrayList med en ArrayList på varje index. identifierare 0 representeras av index 0 i listan. 
där sparas en lista med alla dess grannar. Har även skapat en djupet-först-sökning funktion. Fuktionen tar enbart ca 3 ms för filen med 8 lines. Så om något 
ska förbättras måste det vara den första funktionen. Påverkas mycket av hur stor graf som ska skapas. grafen måste initsialiseras så att alla noder får plats men görs den för stor kommer den ta för mycket utrymme. För en graf med 10 miljoner noder tar det 1123 ms och för en graf
med 100 miljoner går det inte ( out of memory: java heap space)
för på en fil med 7 rader tar depthfirstsearch 98 ms. på en fil med 85 rader 144 ms. på en fil med 1063 rader tar det 199 ms.  (har nu satt grafen till 10 milj noder)
När Grafen sparades som ArrayList<ArrayList<int>> (1063 rader) 1013 ms. När grafen sparas som LinkedList<Integer> adj[] (också en linkedlist) read: 986 ms, dfs: 24 ms. 

Dag 4
overlaps.m4 har 64 056 772 rader. När jag försökte köra mitt program på den riktiga filen: java.lang.OutOfMemoryError: Java heap space
försökte med Graph2 (linkedlist): java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects. 
Försökte öka heapspace med "vmArgs": "-Xmx4048m",  i launch.json filen.
Den stannar på 26 milj. Ökade till 8048. Nu funkar det.63920640


Time for task read: 18964512 ms
Time for task histogram: 13512 ms

number of nodes: 11393435
Nu vet jag antalet noder så ändrar Grafen till en storlek av 11393435 +1. Programmet går nu snabbare. Uppkommer problem när jag kör depthfirstsearch på grafen. 
När det är rekursion läggs allt på en stack så jag ökar storleken med -Xss515m. Det fungerar nu. 


number of components: 317284
number of cliques: 35472
Time for task read: 5460931 ms
Time for task depthfirstsearch: 312982 ms

Dag 5
Försöker föbättra min funktion samt tänka på tidskomplexiteten. Har gjort allt med arraylistor men insett att den kanske skulle köra effektivare med linkedlist? 
Arraylistor måste hela tiden 'rezisas' vilket är onödigt. Dock går det mycket snabbare att komma åt elementen, vet dock inte vad jag borde prioritera. 
Testkörde en gång utan att skapa graf 
Time for task read: 1817930 ms

numberOfEdges: 63962895
Time for task read: 7655093 ms
Time for task histogram: 0 ms
Time for task depthfirstsearch: 1117613 ms

Dag 6
testade att istället ha en hashmap som räknar grannar så räknade jag för varje nod i grafen storleken på grannlistan. Detta verkar ta längre tid dock. 
ska jag kanske ändra så att identifiers inte sparar hela strängen utan enbart en del av den?
ser att antalet kanter skiljer sig numberOfEdges: 63962895 i mitt program  63920640 med scellscript. Konstigt. fil med 1063 rader: 1062 med shellscript, 1063 med mitt program. Ändrade så att om en nod redan finns med bland en annan nods grannar så räknas inte den kanten igen. nu räknas samma fil istället ha 1056 rader.
Kör overlaps.m4 igen. Det tar längre och längre tid mellan varje miljonte rad. 
resultat:
number of edges: 63408137
number of components: 273187
number of cliques: 36418
Time for task read: 11854212 ms
Time for task histogram: 15083 ms
Time for task depthfirstsearch: 1993970 ms

Det tar dock längre tid eftersom jag för varje ny kant behövde använda contains för att kolla om kanten kanten redan finns. 
Testade att ta bort histogrammet nodes och istället för att skapa histogrammet kolla för varje nod storleken på grannlistan.
testade byta till ASCII men det gjorde ingen skillnad för tiden.
private String reEncode(String identifier) {
		byte ptext[] = identifier.getBytes();
		String value = new String(ptext, StandardCharsets.US_ASCII);
		return value;
	}
gjorde en fil med 100 000 rader: 	
number of edges: 99479
number of components: 1452
number of cliques: 0
Time for task read: 2707 ms
Time for task depthfirstsearch: 278 ms

200 000 rader:
number of edges: 198757
number of components: 2433
number of cliques: 1
Time for task read: 3748 ms
Time for task depthfirstsearch: 358 ms

